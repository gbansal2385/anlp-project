{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_bar\n",
    "import torch\n",
    "import tempfile\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling, pipeline\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aryan Bansal was born in London, England. He is the son of a British Army officer, and his mother is a native of India.\n",
      "\n",
      "He is married to a Tamil-speaking woman, who is from Tamil Nadu. They have two children, a son and a daughter. The couple live in a small house in the city of Chennai, India, where they have a house of their own.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\", clean_up_tokenization_spaces=True)\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-125M', pad_token_id=tokenizer.eos_token_id, device=0)\n",
    "with torch.no_grad():\n",
    "    output_text = generator(\n",
    "            \"Aryan Bansal was\",\n",
    "            max_length=1000,\n",
    "            num_beams=3,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=2,\n",
    "            truncation=True\n",
    "        )[0]['generated_text']\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aryan Bansal was a 3 year old boy. He was playing in the park with his friends. They were having a lot of fun.\n",
      "\n",
      "But then, something happened. A gust of wind came and blew away all of their toys. Everyone was sad and started to cry. \n",
      "\n",
      "Aryan, who was feeling very brave, decided to try to find all of his toys. He started to look everywhere, but he couldn't find them. He asked his friends, \"Where did my toys go?\"\n",
      "\n",
      "One of his friends said, \"Don't worry, we will help you find them.\" So they all started looking around the park. After a few minutes, they found all of the toys!\n",
      "\n",
      "ryan was so happy. He thanked his friends for helping him. They all hugged and went back to the park to play.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\", clean_up_tokenization_spaces=True)\n",
    "generator = pipeline('text-generation', model='roneneldan/TinyStories-33M', pad_token_id=tokenizer.eos_token_id, device=0)\n",
    "with torch.no_grad():\n",
    "    output_text = generator(\n",
    "            \"Aryan Bansal was\",\n",
    "            max_length=1000,\n",
    "            num_beams=3,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=3,\n",
    "            truncation=True\n",
    "        )[0]['generated_text']\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0: rl became best friends. They played together every day. The girl was so happy to have a new friend.\n",
      "on 1: p each other when they need it, and they will always be there for you when you need them the most.\"\n",
      "on 2: ed that sometimes, a small gesture of kindness is more powerful than a big tower or a heavy block.\n",
      "on 3:  to share and be kind to others. When we share, everyone is happy and we can all be happy together!\n",
      "on 4: g tree in their yard.\" Tom smiled and said, \"Yes, mom. I love to stretch and play with my friends.\"\n",
      "on 5: ?\" Mom asked. \"This is my pot! It is very special! You have ruined it! How could you be so clumsy?\"\n",
      "on 6: om was clean and he felt much better. The king was so happy to be able to relax and enjoy his bath.\n",
      "on 7: e woolly, ready to himself, he missed and longing for joy, waiting for the sky. Like woofys for one\n",
      "on 8: r reliable friend. And she never had to worry about a bad man taking her precious arrow away again!\n",
      "on 9:  Lily looked and looked for him. Finally, she found Max and they both laughed and had a great time.\n",
      "on 10: f our story: Helping others can bring happiness and friendship to both ourselves and our life too.\"\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on 10: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 11: er and help each other, they can do big things and have more fun than they ever thought was alone.\n",
      "on 12: it's always better to be kind and helpful to others, even if it means giving up something you want.\n",
      "on 13: day painting with bright colors and own ideas. At the end of the day, she was tired but very happy.\n",
      "on 14: ith each other every time they met at the big cliff near the pretty yard of toy box at their homes!\n",
      "on 15:  work. Her mummy smiled too, happy that her daughter had found a way to make something so special.\n",
      "on 16: ture and they had so much fun! They promised each other that they would travel together again soon.\n",
      "on 17: nd they all had fun together on the soft, warm mattress, even though it was hard to run a fast one!\n",
      "on 18: . So, don't be afraid to try new things, because you never know what fun adventures you might have!\n",
      "on 19:  it rained outside, because they knew they would always have each other to keep them warm and dry.\n",
      "on 20: t you lost, if you're ever sad or scared or need a hug or a kind word to make up for your mistake.\"\n",
      "on 21: d. Her face turned red and swollen. How could she make Tom feel better? How can she eat spicy food?\n",
      "on 22: d and showed him what he had found. His dad was so proud of him and they celebrated with a big hug.\n",
      "on 23: ll lived happily ever after, playing and having fun together on Mia's soft, cozy bed every night.\n",
      "on 24: ust like their hero Tom had helped Lily when she needed it most was their kindness and friendship.\n",
      "on 25: on, whenever Tim had money he would share his money with Sue, and they became the best of friends.\n",
      "on 26: their wet clothes and shoes. And they all had a fun day together, even with the frog by their side.\n",
      "on 27:  in the forest. And that is how the story ends, with a bad ending to their day in their small town,\n",
      "on 28: ne you love the day you were brave enough to chase and scare away a little dog like the first time!\n",
      "on 29: was time to go back inside. Sara was sad, but she knew she would have more fun flying the next day.\n",
      "on 30:  jogs together, making new memories and having fun adventures in their cool little park park home.\n",
      "on 31: g fun, even more and try to say thank them as well, until they do this time for a lot at home, too!\n",
      "on 32: n she ran off to show her diary to her mom and dad. They were so proud of their brilliant daughter!\n",
      "on 33:  they waited and waited, and finally the sun came out and dried up all the wet sand from the shore.\n",
      "on 34:  that no matter how wealthy or poor you are, there is always something special waiting to be found!\n",
      "on 35: ven when you are scared at the same time, because you never know what kind of candy you might find!\n",
      "on 36: rom that day on, Peter always remembered to be careful when reaching for things he couldn't reach.\n",
      "on 37: other and work together to solve the problem of how to get their house down from the high ceiling.\n",
      "on 38: traps, just in case they needed to scare away any more curious animals who might try to hurt them.\n",
      "on 39:  They hugged him and told him how proud they were of him for being brave and exploring the unknown.\n",
      "on 40:  you grow and learn and be strong. If you do something wrong, say sorry and try to make up for it.\"\n",
      "on 41: e she would always remember the delicious broccoli she found in her book and how it tasted so good.\n",
      "on 42: The moral of the story is that eating healthy is important for our bodies to be strong and healthy.\n",
      "on 43: spent the afternoon drawing and coloring together, and when they were done, Marie felt much better!\n",
      "on 44: ther and had fun. From that day on they learned that sharing is important and makes everyone happy.\n",
      "on 45: thanked Quick for helping her. From that day on, Quick and Amy played together and had lots of fun.\n",
      "on 46: ld, and May felt the star twinkling in her hand. It was the most beautiful thing May had ever seen.\n",
      "on 47: tree and took a bite of the pear. It was sweet and juicy! Sally smiled and continued her adventure.\n",
      "on 48: n, he always looked out for others who needed help and never forgot the kindness he showed to them.\n",
      "on 49: nds. They would sit together and listen to each other's stories. And they lived happily ever after.\n",
      "|▏⚠︎                                      | (!) 50/27631 [0%] in 6:05.4 (0.14/s) \n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\", clean_up_tokenization_spaces=True)\n",
    "generator = pipeline('text-generation', model='roneneldan/TinyStories-33M', pad_token_id=tokenizer.eos_token_id, device=0)\n",
    "\n",
    "with open(\"../Data/TinyStoriesV2-GPT4-valid.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "stories = data.split(\"<|endoftext|>\")\n",
    "\n",
    "generated_texts_tinystories_gpt4val = []\n",
    "\n",
    "with open(\"../Output/tinystories_output_gpt4val.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    with alive_bar(len(stories), force_tty=True) as bar:\n",
    "        for story in stories:\n",
    "            if len(generated_texts_tinystories_gpt4val) == 50: # testing on 50 stories\n",
    "                break\n",
    "            if not story.strip():  # Skip empty stories\n",
    "                continue\n",
    "            prompt = story.strip()\n",
    "\n",
    "            # Use only the first half of the story as prompt\n",
    "            prompt_len = len(prompt.split()) // 2\n",
    "            prompt = \" \".join(prompt.split()[:prompt_len])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_text = generator(\n",
    "                    prompt,\n",
    "                    max_length=1000,\n",
    "                    num_beams=3,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    num_return_sequences=1,\n",
    "                    no_repeat_ngram_size=2,\n",
    "                    truncation=True\n",
    "                )[0]['generated_text']\n",
    "\n",
    "            print(output_text[-100:])\n",
    "            generated_texts_tinystories_gpt4val.append(output_text)\n",
    "            f.write(output_text + \"\\n<|endoftext|>\\n\")\n",
    "            bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0: her way, this is the best way to learn about the situation and how to deal with it in your own life.\n",
      "on 1: , that's not what this is about. Don't be afraid to ask questions. Ask questions that you can answer\n",
      "on 2:  him again. As he lay there, watching her sleep, it seemed as if he were waking up from a nightmare.\n",
      "on 3: avors. For more information, please visit our website at www.lindsay.com or call us at 866-832-2377.\n",
      "on 4: d that the dog would be okay if Tom stayed with them. After Tom left, he said goodbye and went home.\n",
      "on 5: something like that because he wanted Lily to love him more and to feel more loved than he ever had.\n",
      "on 6: so much better, because he knew that it would be the last time he ever had to live with his parents.\n",
      "on 7: e the only thing that mattered was Max being a great father and being the best mother he'd ever had.\n",
      "on 8: y reliable and has a very long life. If you want to know more about this, you can go to our website.\n",
      "on 9:  make the most of what you have and move forward in life and change your way of thinking and acting.\n",
      "on 10: d are the ones who are more likely to live in your house than in any other place you have ever been.\n",
      "on 11: all dead. It was the first time that I ever saw a dead owl in my life. I was so happy when I saw it.\n",
      "on 12: , please visit my website at www.sue.com. Thanks for stopping by and thank you for visiting my blog.\n",
      "on 13: . Share it with your family                                              \n",
      "       16. Enjoy your work\n",
      "       17. Be inspired\n",
      "       18. Have fun\n",
      "       19. Give your stories a\n",
      "|⚠︎                                       | (!) 14/27631 [0%] in 6:23.9 (0.04/s) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(prompt\u001b[38;5;241m.\u001b[39msplit()[:prompt_len])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 24\u001b[0m     output_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_text[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:])\n\u001b[0;32m     36\u001b[0m generated_texts_gptneo_gpt4val\u001b[38;5;241m.\u001b[39mappend(output_text)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:272\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\pipelines\\base.py:1268\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         )\n\u001b[0;32m   1266\u001b[0m     )\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\pipelines\\base.py:1275\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1274\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1275\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1276\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\pipelines\\base.py:1175\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1174\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1175\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1176\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:370\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    368\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 370\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    371\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\generation\\utils.py:2078\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2070\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2071\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2072\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2073\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2074\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2075\u001b[0m     )\n\u001b[0;32m   2077\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2078\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2079\u001b[0m         input_ids,\n\u001b[0;32m   2080\u001b[0m         beam_scorer,\n\u001b[0;32m   2081\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2082\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2083\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2084\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2085\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2086\u001b[0m     )\n\u001b[0;32m   2088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2089\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2090\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2091\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2092\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2098\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2099\u001b[0m     )\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\generation\\utils.py:3253\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3250\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_text_config())\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[1;32m-> 3253\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   3256\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:1043\u001b[0m, in \u001b[0;36mGPTNeoForCausalLM.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1043\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1059\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:806\u001b[0m, in \u001b[0;36mGPTNeoModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    795\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    796\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    797\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    803\u001b[0m         cache_position,\n\u001b[0;32m    804\u001b[0m     )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 806\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    816\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:529\u001b[0m, in \u001b[0;36mGPTNeoBlock.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[0;32m    527\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    528\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 529\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[0;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:485\u001b[0m, in \u001b[0;36mGPTNeoMLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m    484\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[1;32m--> 485\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[0;32m    487\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\IIITH\\Sem7\\ANLP\\ANLP-Project\\src\\tinystories.env\\lib\\site-packages\\transformers\\activations.py:56\u001b[0m, in \u001b[0;36mNewGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.044715\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\", clean_up_tokenization_spaces=True)\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-125M', pad_token_id=tokenizer.eos_token_id, device=0)\n",
    "\n",
    "with open(\"../Data/TinyStoriesV2-GPT4-valid.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()\n",
    "stories = data.split(\"<|endoftext|>\")\n",
    "\n",
    "generated_texts_gptneo_gpt4val = []\n",
    "\n",
    "with open(\"../Output/gptneo_output_gpt4val.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    with alive_bar(len(stories), force_tty=True) as bar:\n",
    "        for story in stories:\n",
    "            if len(generated_texts_gptneo_gpt4val) == 50:\n",
    "                break\n",
    "            if not story.strip():  # Skip empty stories\n",
    "                continue\n",
    "            prompt = story.strip()\n",
    "\n",
    "            # Use only the first half of the story as prompt\n",
    "            prompt_len = len(prompt.split()) // 2\n",
    "            prompt = \" \".join(prompt.split()[:prompt_len])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_text = generator(\n",
    "                    prompt,\n",
    "                    max_length=1000,\n",
    "                    num_beams=3,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    num_return_sequences=1,\n",
    "                    no_repeat_ngram_size=2,\n",
    "                    truncation=True\n",
    "                )[0]['generated_text']\n",
    "\n",
    "            print(output_text[-100:])\n",
    "            generated_texts_gptneo_gpt4val.append(output_text)\n",
    "            f.write(output_text + \"\\n<|endoftext|>\\n\")\n",
    "            bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary directory: C:\\Users\\aryan\\AppData\\Local\\Temp\\tmpk98ciguo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35337fb31411422ba3cd6baf7f91a422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4b74cdeb274caaacf67342b11ce03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97eebb22fd534e4e977b11989633fba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/156000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65efb083dbe840ed8cec7a9c7f0a1775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    print(f\"Temporary directory: {tmpdir}\")\n",
    "    data_files = {\"train\": \"../Data/TinyStoriesV2-GPT4-train.txt\", \"validation\": \"../Data/TinyStoriesV2-GPT4-valid.txt\"}\n",
    "    dataset = load_dataset(\"text\", data_files=data_files, cache_dir=tmpdir)\n",
    "\n",
    "    # Use 1% of the training and validation data for fine tuning\n",
    "    dataset[\"train\"] = dataset[\"train\"].train_test_split(train_size=0.01)[\"train\"]\n",
    "    dataset[\"validation\"] = dataset[\"validation\"].train_test_split(train_size=0.01)[\"train\"]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\", clean_up_tokenization_spaces=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "        num_proc=torch.cuda.device_count(),\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./finetuned_tinystories\",\n",
    "        per_device_train_batch_size=4,  # Adjust based on your GPU memory\n",
    "        per_device_eval_batch_size=4,\n",
    "        learning_rate=2e-5,\n",
    "        num_train_epochs=3,  # Adjust as needed\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        fp16=True,  # Enable mixed precision training for speedup on compatible GPUs\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"roneneldan/TinyStories-33M\").to(device)\n",
    "    # model.resize_token_embeddings(len(tokenizer))  # Resize if you added a new PAD token\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d23e3871f054204b4f78240b3a91b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5983, 'grad_norm': 14.911356925964355, 'learning_rate': 1.9914871794871796e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6407, 'grad_norm': 17.492216110229492, 'learning_rate': 1.982940170940171e-05, 'epoch': 0.03}\n",
      "{'loss': 1.6284, 'grad_norm': 13.466714859008789, 'learning_rate': 1.9744102564102565e-05, 'epoch': 0.04}\n",
      "{'loss': 1.6251, 'grad_norm': 20.218801498413086, 'learning_rate': 1.965863247863248e-05, 'epoch': 0.05}\n",
      "{'loss': 1.6464, 'grad_norm': 15.818338394165039, 'learning_rate': 1.9573162393162394e-05, 'epoch': 0.06}\n",
      "{'loss': 1.6235, 'grad_norm': 16.174875259399414, 'learning_rate': 1.948769230769231e-05, 'epoch': 0.08}\n",
      "{'loss': 1.6575, 'grad_norm': 13.682311058044434, 'learning_rate': 1.9402222222222223e-05, 'epoch': 0.09}\n",
      "{'loss': 1.6268, 'grad_norm': 13.096839904785156, 'learning_rate': 1.931675213675214e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6279, 'grad_norm': 11.731942176818848, 'learning_rate': 1.9231282051282052e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6282, 'grad_norm': 23.257055282592773, 'learning_rate': 1.9145811965811966e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6245, 'grad_norm': 14.163183212280273, 'learning_rate': 1.906034188034188e-05, 'epoch': 0.14}\n",
      "{'loss': 1.6427, 'grad_norm': 11.32718563079834, 'learning_rate': 1.8975042735042735e-05, 'epoch': 0.15}\n",
      "{'loss': 1.6031, 'grad_norm': 12.015750885009766, 'learning_rate': 1.8889572649572653e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6452, 'grad_norm': 11.045635223388672, 'learning_rate': 1.8804102564102568e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6369, 'grad_norm': 13.681825637817383, 'learning_rate': 1.871863247863248e-05, 'epoch': 0.19}\n",
      "{'loss': 1.629, 'grad_norm': 17.566650390625, 'learning_rate': 1.8633162393162393e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6397, 'grad_norm': 13.63282299041748, 'learning_rate': 1.8547863247863248e-05, 'epoch': 0.22}\n",
      "{'loss': 1.626, 'grad_norm': 11.624981880187988, 'learning_rate': 1.8462564102564106e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6386, 'grad_norm': 11.73610782623291, 'learning_rate': 1.837709401709402e-05, 'epoch': 0.24}\n",
      "{'loss': 1.642, 'grad_norm': 13.071837425231934, 'learning_rate': 1.8291623931623935e-05, 'epoch': 0.26}\n",
      "{'loss': 1.6437, 'grad_norm': 15.882830619812012, 'learning_rate': 1.8206153846153846e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6302, 'grad_norm': 11.293937683105469, 'learning_rate': 1.812068376068376e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6196, 'grad_norm': 13.097707748413086, 'learning_rate': 1.8035213675213678e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6355, 'grad_norm': 15.445043563842773, 'learning_rate': 1.7949743589743592e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6374, 'grad_norm': 9.965953826904297, 'learning_rate': 1.7864273504273507e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6156, 'grad_norm': 9.52259349822998, 'learning_rate': 1.777880341880342e-05, 'epoch': 0.33}\n",
      "{'loss': 1.619, 'grad_norm': 11.522472381591797, 'learning_rate': 1.7693675213675216e-05, 'epoch': 0.35}\n",
      "{'loss': 1.6269, 'grad_norm': 11.124307632446289, 'learning_rate': 1.760820512820513e-05, 'epoch': 0.36}\n",
      "{'loss': 1.6323, 'grad_norm': 20.21674919128418, 'learning_rate': 1.7522735042735045e-05, 'epoch': 0.37}\n",
      "{'loss': 1.6171, 'grad_norm': 12.3836088180542, 'learning_rate': 1.743726495726496e-05, 'epoch': 0.38}\n",
      "{'loss': 1.615, 'grad_norm': 10.49758529663086, 'learning_rate': 1.7351794871794874e-05, 'epoch': 0.4}\n",
      "{'loss': 1.6088, 'grad_norm': 11.475870132446289, 'learning_rate': 1.7266324786324788e-05, 'epoch': 0.41}\n",
      "{'loss': 1.6123, 'grad_norm': 11.748344421386719, 'learning_rate': 1.7180854700854703e-05, 'epoch': 0.42}\n",
      "{'loss': 1.6579, 'grad_norm': 10.278554916381836, 'learning_rate': 1.7095384615384617e-05, 'epoch': 0.44}\n",
      "{'loss': 1.6275, 'grad_norm': 12.62913990020752, 'learning_rate': 1.700991452991453e-05, 'epoch': 0.45}\n",
      "{'loss': 1.6268, 'grad_norm': 14.046950340270996, 'learning_rate': 1.6924615384615386e-05, 'epoch': 0.46}\n",
      "{'loss': 1.6237, 'grad_norm': 9.983315467834473, 'learning_rate': 1.68391452991453e-05, 'epoch': 0.47}\n",
      "{'loss': 1.6157, 'grad_norm': 9.115331649780273, 'learning_rate': 1.6753846153846155e-05, 'epoch': 0.49}\n",
      "{'loss': 1.6378, 'grad_norm': 18.808551788330078, 'learning_rate': 1.666837606837607e-05, 'epoch': 0.5}\n",
      "{'loss': 1.6116, 'grad_norm': 13.750839233398438, 'learning_rate': 1.6582905982905984e-05, 'epoch': 0.51}\n",
      "{'loss': 1.6077, 'grad_norm': 11.166685104370117, 'learning_rate': 1.6497435897435898e-05, 'epoch': 0.53}\n",
      "{'loss': 1.6139, 'grad_norm': 10.64850902557373, 'learning_rate': 1.6411965811965813e-05, 'epoch': 0.54}\n",
      "{'loss': 1.6021, 'grad_norm': 11.674903869628906, 'learning_rate': 1.6326495726495727e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6225, 'grad_norm': 10.529852867126465, 'learning_rate': 1.624102564102564e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6144, 'grad_norm': 16.731063842773438, 'learning_rate': 1.6155555555555556e-05, 'epoch': 0.58}\n",
      "{'loss': 1.613, 'grad_norm': 13.348647117614746, 'learning_rate': 1.607025641025641e-05, 'epoch': 0.59}\n",
      "{'loss': 1.6343, 'grad_norm': 13.645350456237793, 'learning_rate': 1.5984957264957265e-05, 'epoch': 0.6}\n",
      "{'loss': 1.6057, 'grad_norm': 9.496912956237793, 'learning_rate': 1.589948717948718e-05, 'epoch': 0.62}\n",
      "{'loss': 1.6239, 'grad_norm': 9.054427146911621, 'learning_rate': 1.5814017094017094e-05, 'epoch': 0.63}\n",
      "{'loss': 1.6161, 'grad_norm': 9.995338439941406, 'learning_rate': 1.5728547008547012e-05, 'epoch': 0.64}\n",
      "{'loss': 1.6189, 'grad_norm': 12.771478652954102, 'learning_rate': 1.5643076923076926e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5947, 'grad_norm': 9.557173728942871, 'learning_rate': 1.5557606837606837e-05, 'epoch': 0.67}\n",
      "{'loss': 1.6105, 'grad_norm': 12.778650283813477, 'learning_rate': 1.5472136752136752e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6152, 'grad_norm': 8.199873924255371, 'learning_rate': 1.5386666666666666e-05, 'epoch': 0.69}\n",
      "{'loss': 1.609, 'grad_norm': 9.852826118469238, 'learning_rate': 1.5301367521367524e-05, 'epoch': 0.71}\n",
      "{'loss': 1.5995, 'grad_norm': 10.623303413391113, 'learning_rate': 1.5215897435897437e-05, 'epoch': 0.72}\n",
      "{'loss': 1.6088, 'grad_norm': 10.669438362121582, 'learning_rate': 1.5130598290598293e-05, 'epoch': 0.73}\n",
      "{'loss': 1.5967, 'grad_norm': 10.030759811401367, 'learning_rate': 1.5045128205128206e-05, 'epoch': 0.74}\n",
      "{'loss': 1.6128, 'grad_norm': 9.907984733581543, 'learning_rate': 1.495965811965812e-05, 'epoch': 0.76}\n",
      "{'loss': 1.5943, 'grad_norm': 14.033074378967285, 'learning_rate': 1.4874188034188035e-05, 'epoch': 0.77}\n",
      "{'loss': 1.6052, 'grad_norm': 15.277020454406738, 'learning_rate': 1.478871794871795e-05, 'epoch': 0.78}\n",
      "{'loss': 1.6084, 'grad_norm': 10.543696403503418, 'learning_rate': 1.4703247863247865e-05, 'epoch': 0.79}\n",
      "{'loss': 1.6253, 'grad_norm': 8.773801803588867, 'learning_rate': 1.461777777777778e-05, 'epoch': 0.81}\n",
      "{'loss': 1.6151, 'grad_norm': 8.98718547821045, 'learning_rate': 1.4532307692307694e-05, 'epoch': 0.82}\n",
      "{'loss': 1.6221, 'grad_norm': 10.794248580932617, 'learning_rate': 1.4446837606837607e-05, 'epoch': 0.83}\n",
      "{'loss': 1.5992, 'grad_norm': 10.756778717041016, 'learning_rate': 1.4361538461538462e-05, 'epoch': 0.85}\n",
      "{'loss': 1.6117, 'grad_norm': 13.306551933288574, 'learning_rate': 1.4276239316239318e-05, 'epoch': 0.86}\n",
      "{'loss': 1.6092, 'grad_norm': 13.329968452453613, 'learning_rate': 1.4190769230769232e-05, 'epoch': 0.87}\n",
      "{'loss': 1.5999, 'grad_norm': 12.327119827270508, 'learning_rate': 1.4105299145299147e-05, 'epoch': 0.88}\n",
      "{'loss': 1.5757, 'grad_norm': 9.343839645385742, 'learning_rate': 1.4019829059829063e-05, 'epoch': 0.9}\n",
      "{'loss': 1.6102, 'grad_norm': 10.785886764526367, 'learning_rate': 1.3934529914529916e-05, 'epoch': 0.91}\n",
      "{'loss': 1.6185, 'grad_norm': 10.684629440307617, 'learning_rate': 1.384905982905983e-05, 'epoch': 0.92}\n",
      "{'loss': 1.6034, 'grad_norm': 18.8637638092041, 'learning_rate': 1.3763589743589745e-05, 'epoch': 0.94}\n",
      "{'loss': 1.5917, 'grad_norm': 8.212302207946777, 'learning_rate': 1.3678119658119659e-05, 'epoch': 0.95}\n",
      "{'loss': 1.5984, 'grad_norm': 8.734042167663574, 'learning_rate': 1.3592649572649575e-05, 'epoch': 0.96}\n",
      "{'loss': 1.6131, 'grad_norm': 10.8418607711792, 'learning_rate': 1.350717948717949e-05, 'epoch': 0.97}\n",
      "{'loss': 1.5707, 'grad_norm': 13.505382537841797, 'learning_rate': 1.3421709401709402e-05, 'epoch': 0.99}\n",
      "{'loss': 1.591, 'grad_norm': 10.554595947265625, 'learning_rate': 1.3336239316239317e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc85ac70f444942a07e77fed0210c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 55.2124, 'eval_samples_per_second': 28.581, 'eval_steps_per_second': 7.154, 'epoch': 1.0}\n",
      "{'loss': 1.3473, 'grad_norm': 12.93578815460205, 'learning_rate': 1.3250940170940171e-05, 'epoch': 1.01}\n",
      "{'loss': 1.3627, 'grad_norm': 26.647449493408203, 'learning_rate': 1.3165470085470087e-05, 'epoch': 1.03}\n",
      "{'loss': 1.3457, 'grad_norm': 10.83144760131836, 'learning_rate': 1.3080000000000002e-05, 'epoch': 1.04}\n",
      "{'loss': 1.3758, 'grad_norm': 11.695415496826172, 'learning_rate': 1.2994700854700856e-05, 'epoch': 1.05}\n",
      "{'loss': 1.3625, 'grad_norm': 25.218990325927734, 'learning_rate': 1.290923076923077e-05, 'epoch': 1.06}\n",
      "{'loss': 1.3572, 'grad_norm': 13.15750789642334, 'learning_rate': 1.2823760683760684e-05, 'epoch': 1.08}\n",
      "{'loss': 1.3648, 'grad_norm': 16.392419815063477, 'learning_rate': 1.27382905982906e-05, 'epoch': 1.09}\n",
      "{'loss': 1.3694, 'grad_norm': 8.822991371154785, 'learning_rate': 1.2652820512820514e-05, 'epoch': 1.1}\n",
      "{'loss': 1.3676, 'grad_norm': 11.997621536254883, 'learning_rate': 1.2567350427350429e-05, 'epoch': 1.12}\n",
      "{'loss': 1.3792, 'grad_norm': 13.406360626220703, 'learning_rate': 1.2481880341880343e-05, 'epoch': 1.13}\n",
      "{'loss': 1.3642, 'grad_norm': 15.79375171661377, 'learning_rate': 1.2396410256410259e-05, 'epoch': 1.14}\n",
      "{'loss': 1.3842, 'grad_norm': 14.92206859588623, 'learning_rate': 1.2310940170940172e-05, 'epoch': 1.15}\n",
      "{'loss': 1.3705, 'grad_norm': 9.919299125671387, 'learning_rate': 1.2225470085470086e-05, 'epoch': 1.17}\n",
      "{'loss': 1.3687, 'grad_norm': 12.071044921875, 'learning_rate': 1.2140170940170941e-05, 'epoch': 1.18}\n",
      "{'loss': 1.3682, 'grad_norm': 10.729138374328613, 'learning_rate': 1.2054700854700855e-05, 'epoch': 1.19}\n",
      "{'loss': 1.367, 'grad_norm': 12.776755332946777, 'learning_rate': 1.1969230769230771e-05, 'epoch': 1.21}\n",
      "{'loss': 1.3939, 'grad_norm': 10.752569198608398, 'learning_rate': 1.1883760683760686e-05, 'epoch': 1.22}\n",
      "{'loss': 1.3866, 'grad_norm': 18.07126808166504, 'learning_rate': 1.1798290598290599e-05, 'epoch': 1.23}\n",
      "{'loss': 1.3711, 'grad_norm': 13.945881843566895, 'learning_rate': 1.1712820512820513e-05, 'epoch': 1.24}\n",
      "{'loss': 1.3651, 'grad_norm': 10.817577362060547, 'learning_rate': 1.1627350427350427e-05, 'epoch': 1.26}\n",
      "{'loss': 1.3709, 'grad_norm': 10.04979419708252, 'learning_rate': 1.1542051282051284e-05, 'epoch': 1.27}\n",
      "{'loss': 1.3694, 'grad_norm': 20.278644561767578, 'learning_rate': 1.1456581196581198e-05, 'epoch': 1.28}\n",
      "{'loss': 1.3678, 'grad_norm': 12.396561622619629, 'learning_rate': 1.1371111111111113e-05, 'epoch': 1.29}\n",
      "{'loss': 1.3858, 'grad_norm': 10.204068183898926, 'learning_rate': 1.1285641025641027e-05, 'epoch': 1.31}\n",
      "{'loss': 1.3934, 'grad_norm': 11.828082084655762, 'learning_rate': 1.120034188034188e-05, 'epoch': 1.32}\n",
      "{'loss': 1.3609, 'grad_norm': 11.95144271850586, 'learning_rate': 1.1114871794871796e-05, 'epoch': 1.33}\n",
      "{'loss': 1.342, 'grad_norm': 10.000892639160156, 'learning_rate': 1.102940170940171e-05, 'epoch': 1.35}\n",
      "{'loss': 1.3704, 'grad_norm': 11.645718574523926, 'learning_rate': 1.0944102564102565e-05, 'epoch': 1.36}\n",
      "{'loss': 1.3607, 'grad_norm': 18.937728881835938, 'learning_rate': 1.0858632478632481e-05, 'epoch': 1.37}\n",
      "{'loss': 1.3861, 'grad_norm': 11.081599235534668, 'learning_rate': 1.0773162393162392e-05, 'epoch': 1.38}\n",
      "{'loss': 1.3928, 'grad_norm': 14.756583213806152, 'learning_rate': 1.0687692307692308e-05, 'epoch': 1.4}\n",
      "{'loss': 1.3816, 'grad_norm': 14.153902053833008, 'learning_rate': 1.0602222222222223e-05, 'epoch': 1.41}\n",
      "{'loss': 1.3963, 'grad_norm': 10.224199295043945, 'learning_rate': 1.0516923076923077e-05, 'epoch': 1.42}\n",
      "{'loss': 1.3856, 'grad_norm': 14.803807258605957, 'learning_rate': 1.0431452991452993e-05, 'epoch': 1.44}\n",
      "{'loss': 1.3739, 'grad_norm': 13.184160232543945, 'learning_rate': 1.0345982905982908e-05, 'epoch': 1.45}\n",
      "{'loss': 1.3854, 'grad_norm': 11.391382217407227, 'learning_rate': 1.0260512820512822e-05, 'epoch': 1.46}\n",
      "{'loss': 1.3577, 'grad_norm': 12.15350341796875, 'learning_rate': 1.0175042735042735e-05, 'epoch': 1.47}\n",
      "{'loss': 1.3923, 'grad_norm': 11.397180557250977, 'learning_rate': 1.008957264957265e-05, 'epoch': 1.49}\n",
      "{'loss': 1.3918, 'grad_norm': 12.17785358428955, 'learning_rate': 1.0004102564102564e-05, 'epoch': 1.5}\n",
      "{'loss': 1.4128, 'grad_norm': 12.712614059448242, 'learning_rate': 9.91863247863248e-06, 'epoch': 1.51}\n",
      "{'loss': 1.3927, 'grad_norm': 17.180992126464844, 'learning_rate': 9.833162393162394e-06, 'epoch': 1.53}\n",
      "{'loss': 1.3575, 'grad_norm': 12.615166664123535, 'learning_rate': 9.747863247863249e-06, 'epoch': 1.54}\n",
      "{'loss': 1.3917, 'grad_norm': 23.30141258239746, 'learning_rate': 9.662393162393163e-06, 'epoch': 1.55}\n",
      "{'loss': 1.4157, 'grad_norm': 11.986169815063477, 'learning_rate': 9.576923076923078e-06, 'epoch': 1.56}\n",
      "{'loss': 1.387, 'grad_norm': 11.18821907043457, 'learning_rate': 9.491452991452992e-06, 'epoch': 1.58}\n",
      "{'loss': 1.3811, 'grad_norm': 18.2240047454834, 'learning_rate': 9.405982905982907e-06, 'epoch': 1.59}\n",
      "{'loss': 1.3802, 'grad_norm': 11.442338943481445, 'learning_rate': 9.320683760683761e-06, 'epoch': 1.6}\n",
      "{'loss': 1.3532, 'grad_norm': 19.740917205810547, 'learning_rate': 9.235213675213676e-06, 'epoch': 1.62}\n",
      "{'loss': 1.3838, 'grad_norm': 12.549921035766602, 'learning_rate': 9.14974358974359e-06, 'epoch': 1.63}\n",
      "{'loss': 1.3677, 'grad_norm': 17.495548248291016, 'learning_rate': 9.064273504273505e-06, 'epoch': 1.64}\n",
      "{'loss': 1.3881, 'grad_norm': 25.475072860717773, 'learning_rate': 8.978803418803419e-06, 'epoch': 1.65}\n",
      "{'loss': 1.3791, 'grad_norm': 11.941329956054688, 'learning_rate': 8.893333333333333e-06, 'epoch': 1.67}\n",
      "{'loss': 1.3716, 'grad_norm': 13.85521411895752, 'learning_rate': 8.807863247863248e-06, 'epoch': 1.68}\n",
      "{'loss': 1.383, 'grad_norm': 10.940044403076172, 'learning_rate': 8.722393162393164e-06, 'epoch': 1.69}\n",
      "{'loss': 1.3707, 'grad_norm': 14.37989330291748, 'learning_rate': 8.637264957264959e-06, 'epoch': 1.71}\n",
      "{'loss': 1.3806, 'grad_norm': 12.011789321899414, 'learning_rate': 8.551794871794873e-06, 'epoch': 1.72}\n",
      "{'loss': 1.4044, 'grad_norm': 10.493988990783691, 'learning_rate': 8.466324786324786e-06, 'epoch': 1.73}\n",
      "{'loss': 1.386, 'grad_norm': 13.000432014465332, 'learning_rate': 8.380854700854702e-06, 'epoch': 1.74}\n",
      "{'loss': 1.3706, 'grad_norm': 9.358642578125, 'learning_rate': 8.295384615384616e-06, 'epoch': 1.76}\n",
      "{'loss': 1.3714, 'grad_norm': 11.052385330200195, 'learning_rate': 8.210085470085471e-06, 'epoch': 1.77}\n",
      "{'loss': 1.3573, 'grad_norm': 11.078946113586426, 'learning_rate': 8.124615384615386e-06, 'epoch': 1.78}\n",
      "{'loss': 1.3743, 'grad_norm': 17.02627182006836, 'learning_rate': 8.0391452991453e-06, 'epoch': 1.79}\n",
      "{'loss': 1.3775, 'grad_norm': 11.663734436035156, 'learning_rate': 7.953675213675214e-06, 'epoch': 1.81}\n",
      "{'loss': 1.3734, 'grad_norm': 10.84732437133789, 'learning_rate': 7.868376068376069e-06, 'epoch': 1.82}\n",
      "{'loss': 1.3906, 'grad_norm': 11.947551727294922, 'learning_rate': 7.782905982905983e-06, 'epoch': 1.83}\n",
      "{'loss': 1.3646, 'grad_norm': 15.452813148498535, 'learning_rate': 7.697435897435898e-06, 'epoch': 1.85}\n",
      "{'loss': 1.3817, 'grad_norm': 10.779151916503906, 'learning_rate': 7.611965811965812e-06, 'epoch': 1.86}\n",
      "{'loss': 1.3768, 'grad_norm': 12.46994686126709, 'learning_rate': 7.526666666666668e-06, 'epoch': 1.87}\n",
      "{'loss': 1.3812, 'grad_norm': 16.32285499572754, 'learning_rate': 7.441196581196581e-06, 'epoch': 1.88}\n",
      "{'loss': 1.3519, 'grad_norm': 10.51803970336914, 'learning_rate': 7.355897435897437e-06, 'epoch': 1.9}\n",
      "{'loss': 1.3922, 'grad_norm': 14.623743057250977, 'learning_rate': 7.270427350427351e-06, 'epoch': 1.91}\n",
      "{'loss': 1.3891, 'grad_norm': 16.535425186157227, 'learning_rate': 7.184957264957266e-06, 'epoch': 1.92}\n",
      "{'loss': 1.3901, 'grad_norm': 9.360250473022461, 'learning_rate': 7.09948717948718e-06, 'epoch': 1.94}\n",
      "{'loss': 1.3791, 'grad_norm': 9.492645263671875, 'learning_rate': 7.0141880341880355e-06, 'epoch': 1.95}\n",
      "{'loss': 1.3554, 'grad_norm': 11.967225074768066, 'learning_rate': 6.928717948717949e-06, 'epoch': 1.96}\n",
      "{'loss': 1.3932, 'grad_norm': 10.990537643432617, 'learning_rate': 6.8432478632478635e-06, 'epoch': 1.97}\n",
      "{'loss': 1.3721, 'grad_norm': 10.963546752929688, 'learning_rate': 6.757777777777779e-06, 'epoch': 1.99}\n",
      "{'loss': 1.3878, 'grad_norm': 12.48460578918457, 'learning_rate': 6.672307692307692e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09671692c7b8498eaf4a77a96b0f9eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 20.7012, 'eval_samples_per_second': 76.227, 'eval_steps_per_second': 19.081, 'epoch': 2.0}\n",
      "{'loss': 1.1491, 'grad_norm': 10.59494686126709, 'learning_rate': 6.586837606837608e-06, 'epoch': 2.01}\n",
      "{'loss': 1.146, 'grad_norm': 12.936086654663086, 'learning_rate': 6.501367521367522e-06, 'epoch': 2.03}\n",
      "{'loss': 1.1507, 'grad_norm': 12.761543273925781, 'learning_rate': 6.4158974358974365e-06, 'epoch': 2.04}\n",
      "{'loss': 1.1478, 'grad_norm': 14.555933952331543, 'learning_rate': 6.330427350427351e-06, 'epoch': 2.05}\n",
      "{'loss': 1.1525, 'grad_norm': 15.432066917419434, 'learning_rate': 6.244957264957265e-06, 'epoch': 2.06}\n",
      "{'loss': 1.1516, 'grad_norm': 12.2783784866333, 'learning_rate': 6.1594871794871806e-06, 'epoch': 2.08}\n",
      "{'loss': 1.1448, 'grad_norm': 9.123688697814941, 'learning_rate': 6.074017094017095e-06, 'epoch': 2.09}\n",
      "{'loss': 1.1423, 'grad_norm': 14.517699241638184, 'learning_rate': 5.9885470085470086e-06, 'epoch': 2.1}\n",
      "{'loss': 1.1512, 'grad_norm': 10.241252899169922, 'learning_rate': 5.903076923076924e-06, 'epoch': 2.12}\n",
      "{'loss': 1.1721, 'grad_norm': 11.228477478027344, 'learning_rate': 5.817606837606838e-06, 'epoch': 2.13}\n",
      "{'loss': 1.1761, 'grad_norm': 16.76984977722168, 'learning_rate': 5.732136752136752e-06, 'epoch': 2.14}\n",
      "{'loss': 1.1571, 'grad_norm': 30.86056137084961, 'learning_rate': 5.646666666666667e-06, 'epoch': 2.15}\n",
      "{'loss': 1.1692, 'grad_norm': 13.397740364074707, 'learning_rate': 5.5613675213675226e-06, 'epoch': 2.17}\n",
      "{'loss': 1.1588, 'grad_norm': 13.460461616516113, 'learning_rate': 5.475897435897436e-06, 'epoch': 2.18}\n",
      "{'loss': 1.161, 'grad_norm': 11.491670608520508, 'learning_rate': 5.3904273504273506e-06, 'epoch': 2.19}\n",
      "{'loss': 1.1636, 'grad_norm': 11.404987335205078, 'learning_rate': 5.304957264957266e-06, 'epoch': 2.21}\n",
      "{'loss': 1.1501, 'grad_norm': 14.316640853881836, 'learning_rate': 5.21948717948718e-06, 'epoch': 2.22}\n",
      "{'loss': 1.1578, 'grad_norm': 15.102874755859375, 'learning_rate': 5.134017094017094e-06, 'epoch': 2.23}\n",
      "{'loss': 1.1676, 'grad_norm': 19.746984481811523, 'learning_rate': 5.048717948717949e-06, 'epoch': 2.24}\n",
      "{'loss': 1.1658, 'grad_norm': 13.131436347961426, 'learning_rate': 4.963247863247864e-06, 'epoch': 2.26}\n",
      "{'loss': 1.1673, 'grad_norm': 13.28918743133545, 'learning_rate': 4.877948717948718e-06, 'epoch': 2.27}\n",
      "{'loss': 1.1497, 'grad_norm': 13.062884330749512, 'learning_rate': 4.792478632478633e-06, 'epoch': 2.28}\n",
      "{'loss': 1.167, 'grad_norm': 11.2969331741333, 'learning_rate': 4.707008547008547e-06, 'epoch': 2.29}\n",
      "{'loss': 1.1661, 'grad_norm': 18.147687911987305, 'learning_rate': 4.621538461538462e-06, 'epoch': 2.31}\n",
      "{'loss': 1.1783, 'grad_norm': 15.105525970458984, 'learning_rate': 4.536068376068377e-06, 'epoch': 2.32}\n",
      "{'loss': 1.1817, 'grad_norm': 13.31460189819336, 'learning_rate': 4.4507692307692315e-06, 'epoch': 2.33}\n",
      "{'loss': 1.1586, 'grad_norm': 16.55576515197754, 'learning_rate': 4.365299145299146e-06, 'epoch': 2.35}\n",
      "{'loss': 1.1464, 'grad_norm': 15.075735092163086, 'learning_rate': 4.27982905982906e-06, 'epoch': 2.36}\n",
      "{'loss': 1.1683, 'grad_norm': 13.804193496704102, 'learning_rate': 4.194358974358975e-06, 'epoch': 2.37}\n",
      "{'loss': 1.1759, 'grad_norm': 31.355266571044922, 'learning_rate': 4.108888888888889e-06, 'epoch': 2.38}\n",
      "{'loss': 1.1757, 'grad_norm': 13.201292991638184, 'learning_rate': 4.023418803418804e-06, 'epoch': 2.4}\n",
      "{'loss': 1.1561, 'grad_norm': 12.518431663513184, 'learning_rate': 3.937948717948718e-06, 'epoch': 2.41}\n",
      "{'loss': 1.1722, 'grad_norm': 12.115169525146484, 'learning_rate': 3.8524786324786324e-06, 'epoch': 2.42}\n",
      "{'loss': 1.1612, 'grad_norm': 17.724918365478516, 'learning_rate': 3.7670085470085473e-06, 'epoch': 2.44}\n",
      "{'loss': 1.1652, 'grad_norm': 9.837977409362793, 'learning_rate': 3.681538461538462e-06, 'epoch': 2.45}\n",
      "{'loss': 1.145, 'grad_norm': 18.496994018554688, 'learning_rate': 3.5964102564102565e-06, 'epoch': 2.46}\n",
      "{'loss': 1.1528, 'grad_norm': 16.0002498626709, 'learning_rate': 3.5109401709401714e-06, 'epoch': 2.47}\n",
      "{'loss': 1.1685, 'grad_norm': 18.19172477722168, 'learning_rate': 3.4254700854700858e-06, 'epoch': 2.49}\n",
      "{'loss': 1.1629, 'grad_norm': 12.371296882629395, 'learning_rate': 3.3400000000000006e-06, 'epoch': 2.5}\n",
      "{'loss': 1.1709, 'grad_norm': 10.908570289611816, 'learning_rate': 3.2545299145299146e-06, 'epoch': 2.51}\n",
      "{'loss': 1.1699, 'grad_norm': 16.729225158691406, 'learning_rate': 3.1690598290598295e-06, 'epoch': 2.53}\n",
      "{'loss': 1.1529, 'grad_norm': 10.832239151000977, 'learning_rate': 3.083589743589744e-06, 'epoch': 2.54}\n",
      "{'loss': 1.1736, 'grad_norm': 11.917189598083496, 'learning_rate': 2.9982905982905985e-06, 'epoch': 2.55}\n",
      "{'loss': 1.1542, 'grad_norm': 11.505790710449219, 'learning_rate': 2.912820512820513e-06, 'epoch': 2.56}\n",
      "{'loss': 1.1805, 'grad_norm': 12.471314430236816, 'learning_rate': 2.8273504273504278e-06, 'epoch': 2.58}\n",
      "{'loss': 1.16, 'grad_norm': 16.9620361328125, 'learning_rate': 2.7418803418803418e-06, 'epoch': 2.59}\n",
      "{'loss': 1.1867, 'grad_norm': 14.780198097229004, 'learning_rate': 2.6564102564102566e-06, 'epoch': 2.6}\n",
      "{'loss': 1.1666, 'grad_norm': 11.599675178527832, 'learning_rate': 2.570940170940171e-06, 'epoch': 2.62}\n",
      "{'loss': 1.1564, 'grad_norm': 12.851849555969238, 'learning_rate': 2.4854700854700855e-06, 'epoch': 2.63}\n",
      "{'loss': 1.1616, 'grad_norm': 17.702579498291016, 'learning_rate': 2.40017094017094e-06, 'epoch': 2.64}\n",
      "{'loss': 1.1672, 'grad_norm': 10.554702758789062, 'learning_rate': 2.314700854700855e-06, 'epoch': 2.65}\n",
      "{'loss': 1.1775, 'grad_norm': 13.713207244873047, 'learning_rate': 2.2292307692307694e-06, 'epoch': 2.67}\n",
      "{'loss': 1.1759, 'grad_norm': 13.77939510345459, 'learning_rate': 2.1437606837606838e-06, 'epoch': 2.68}\n",
      "{'loss': 1.1715, 'grad_norm': 0.0, 'learning_rate': 2.058461538461539e-06, 'epoch': 2.69}\n",
      "{'loss': 1.1466, 'grad_norm': 11.435493469238281, 'learning_rate': 1.9729914529914532e-06, 'epoch': 2.71}\n",
      "{'loss': 1.1648, 'grad_norm': 17.62528419494629, 'learning_rate': 1.8875213675213677e-06, 'epoch': 2.72}\n",
      "{'loss': 1.1375, 'grad_norm': 9.704795837402344, 'learning_rate': 1.8020512820512823e-06, 'epoch': 2.73}\n",
      "{'loss': 1.1564, 'grad_norm': 35.97626876831055, 'learning_rate': 1.7165811965811967e-06, 'epoch': 2.74}\n",
      "{'loss': 1.1566, 'grad_norm': 10.916794776916504, 'learning_rate': 1.6311111111111114e-06, 'epoch': 2.76}\n",
      "{'loss': 1.1528, 'grad_norm': 26.839990615844727, 'learning_rate': 1.5456410256410256e-06, 'epoch': 2.77}\n",
      "{'loss': 1.1441, 'grad_norm': 13.114200592041016, 'learning_rate': 1.4603418803418804e-06, 'epoch': 2.78}\n",
      "{'loss': 1.1684, 'grad_norm': 11.32710075378418, 'learning_rate': 1.3748717948717948e-06, 'epoch': 2.79}\n",
      "{'loss': 1.1416, 'grad_norm': 15.757648468017578, 'learning_rate': 1.2894017094017094e-06, 'epoch': 2.81}\n",
      "{'loss': 1.1425, 'grad_norm': 13.160869598388672, 'learning_rate': 1.203931623931624e-06, 'epoch': 2.82}\n",
      "{'loss': 1.1617, 'grad_norm': 15.164131164550781, 'learning_rate': 1.1184615384615385e-06, 'epoch': 2.83}\n",
      "{'loss': 1.1723, 'grad_norm': 12.5908784866333, 'learning_rate': 1.0331623931623933e-06, 'epoch': 2.85}\n",
      "{'loss': 1.1529, 'grad_norm': 21.750823974609375, 'learning_rate': 9.476923076923078e-07, 'epoch': 2.86}\n",
      "{'loss': 1.1613, 'grad_norm': 17.372234344482422, 'learning_rate': 8.622222222222224e-07, 'epoch': 2.87}\n",
      "{'loss': 1.1593, 'grad_norm': 15.045711517333984, 'learning_rate': 7.767521367521368e-07, 'epoch': 2.88}\n",
      "{'loss': 1.1331, 'grad_norm': 17.452280044555664, 'learning_rate': 6.912820512820513e-07, 'epoch': 2.9}\n",
      "{'loss': 1.1731, 'grad_norm': 12.715011596679688, 'learning_rate': 6.058119658119659e-07, 'epoch': 2.91}\n",
      "{'loss': 1.1662, 'grad_norm': 15.249601364135742, 'learning_rate': 5.203418803418804e-07, 'epoch': 2.92}\n",
      "{'loss': 1.1603, 'grad_norm': 10.024389266967773, 'learning_rate': 4.3487179487179487e-07, 'epoch': 2.94}\n",
      "{'loss': 1.1484, 'grad_norm': 14.583991050720215, 'learning_rate': 3.495726495726496e-07, 'epoch': 2.95}\n",
      "{'loss': 1.1637, 'grad_norm': 11.889537811279297, 'learning_rate': 2.641025641025641e-07, 'epoch': 2.96}\n",
      "{'loss': 1.1434, 'grad_norm': 12.145575523376465, 'learning_rate': 1.7880341880341882e-07, 'epoch': 2.97}\n",
      "{'loss': 1.1641, 'grad_norm': 11.105847358703613, 'learning_rate': 9.333333333333335e-08, 'epoch': 2.99}\n",
      "{'loss': 1.1412, 'grad_norm': 13.562801361083984, 'learning_rate': 7.863247863247864e-09, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da71c3f8cd404cfba3d7f1aad86fe635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 20.7663, 'eval_samples_per_second': 75.988, 'eval_steps_per_second': 19.021, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 24414.3472, 'train_samples_per_second': 19.169, 'train_steps_per_second': 4.792, 'train_loss': 1.3849269257895966, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=117000, training_loss=1.3849269257895966, metrics={'train_runtime': 24414.3472, 'train_samples_per_second': 19.169, 'train_steps_per_second': 4.792, 'total_flos': 4.0749779386368e+16, 'train_loss': 1.3849269257895966, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./finetuned_tinystories\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinystories.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
